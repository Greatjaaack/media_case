{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa1028d7e37ec581",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:18:52.793933Z",
     "start_time": "2024-02-21T08:18:52.438031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       название_канала                                    ссылка_на_канал  \\\n0                   A4  http://www.youtube.com/channel/UC2tsySbe9TNrI-...   \n1      Kuplinov ► Play  http://www.youtube.com/channel/UCdKuE7a2QZeHPh...   \n2  Натурал Альбертович  http://www.youtube.com/channel/UCE7f6y9VGVdZEt...   \n3            ExileShow  http://www.youtube.com/channel/UC6JRrn_7Qe1CZB...   \n4        Gufee.medalin  http://www.youtube.com/channel/UC7VUPJfRyt57Xo...   \n\n                                     описание_канала  \\\n0  Канал называется А4, почему так? Тебе нужно за...   \n1  Здесь можно поржать, отложить кирпичей, снять ...   \n2                         Всем спасибо за подписку❤️   \n3  Я не знаю, зачем создал этот канал, но он врод...   \n4                    ❌Самый молодой режиссёр страны❌   \n\n                              Названия_видео_роликов       метка_класса  \n0  1,000 ЗАДАНИЙ за 24 ЧАСА ЧЕЛЛЕНДЖ ! ** 3 Часть...  Развлечения, Юмор  \n1  ПРЕДАТЕЛЬ ► Resident Evil HD Remaster #7\\nВСЕЛ...         Юмор, Игры  \n2  СМЕШНЫЕ ВИДЕО СБОРНИК / ЮМОР и ПРИКОЛЫ / Свежи...               Юмор  \n3  Самый Везучий Выиграет 200.000! (Горилла, Коре...        Развлечения  \n4  ТРЕТИЙ ЭТАП ОТНОШЕНИЙ - ТРЕЙЛЕР СЕРИАЛА (ПРЕМЬ...               Кино  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>название_канала</th>\n      <th>ссылка_на_канал</th>\n      <th>описание_канала</th>\n      <th>Названия_видео_роликов</th>\n      <th>метка_класса</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A4</td>\n      <td>http://www.youtube.com/channel/UC2tsySbe9TNrI-...</td>\n      <td>Канал называется А4, почему так? Тебе нужно за...</td>\n      <td>1,000 ЗАДАНИЙ за 24 ЧАСА ЧЕЛЛЕНДЖ ! ** 3 Часть...</td>\n      <td>Развлечения, Юмор</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Kuplinov ► Play</td>\n      <td>http://www.youtube.com/channel/UCdKuE7a2QZeHPh...</td>\n      <td>Здесь можно поржать, отложить кирпичей, снять ...</td>\n      <td>ПРЕДАТЕЛЬ ► Resident Evil HD Remaster #7\\nВСЕЛ...</td>\n      <td>Юмор, Игры</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Натурал Альбертович</td>\n      <td>http://www.youtube.com/channel/UCE7f6y9VGVdZEt...</td>\n      <td>Всем спасибо за подписку❤️</td>\n      <td>СМЕШНЫЕ ВИДЕО СБОРНИК / ЮМОР и ПРИКОЛЫ / Свежи...</td>\n      <td>Юмор</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ExileShow</td>\n      <td>http://www.youtube.com/channel/UC6JRrn_7Qe1CZB...</td>\n      <td>Я не знаю, зачем создал этот канал, но он врод...</td>\n      <td>Самый Везучий Выиграет 200.000! (Горилла, Коре...</td>\n      <td>Развлечения</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Gufee.medalin</td>\n      <td>http://www.youtube.com/channel/UC7VUPJfRyt57Xo...</td>\n      <td>❌Самый молодой режиссёр страны❌</td>\n      <td>ТРЕТИЙ ЭТАП ОТНОШЕНИЙ - ТРЕЙЛЕР СЕРИАЛА (ПРЕМЬ...</td>\n      <td>Кино</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'result.csv'\n",
    "data = pd.read_csv(file_path, sep='|')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер оригинального датасета: (5251, 7)\n",
      "Размер очищенного датасета: (5246, 7)\n"
     ]
    }
   ],
   "source": [
    "from cleantext import clean\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = clean(\n",
    "        text,\n",
    "        fix_unicode=True,\n",
    "        to_ascii=False,\n",
    "        lower=True,\n",
    "        no_line_breaks=True,\n",
    "        no_urls=True,\n",
    "        no_emails=True,\n",
    "        no_phone_numbers=True,\n",
    "        no_numbers=False,\n",
    "        no_digits=True,\n",
    "        no_currency_symbols=True,\n",
    "        no_punct=True,\n",
    "        no_emoji=True,\n",
    "        replace_with_url=\"\",\n",
    "        replace_with_email=\"\",\n",
    "        replace_with_phone_number=\"\",\n",
    "        replace_with_digit=\"\",\n",
    "        lang=\"ru\",\n",
    "    )\n",
    "\n",
    "    text = re.sub(r'►|---', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "data['описание_канала'] = data['описание_канала'].apply(clean_text)\n",
    "data['Названия_видео_роликов'] = data['Названия_видео_роликов'].apply(clean_text)\n",
    "data['метка_класса'] = data['метка_класса'].apply(lambda x: x.split(', ') if isinstance(x, str) else [])\n",
    "all_classes = set([cls for sublist in data['метка_класса'] for cls in sublist])\n",
    "unique_classes = list(all_classes)\n",
    "\n",
    "class_to_index = {classname: index for index, classname in enumerate(unique_classes)}\n",
    "data['метка_класса_id'] = data['метка_класса'].apply(\n",
    "    lambda classes: [\n",
    "        class_to_index[cls]\n",
    "        for cls in classes\n",
    "        if cls in class_to_index\n",
    "    ]\n",
    ")\n",
    "data['combined_text'] = data['название_канала'] + ' ' + data['описание_канала'] + ' ' + data['Названия_видео_роликов']\n",
    "nan_rows = data[data['название_канала'].isna() | data['описание_канала'].isna() | data['Названия_видео_роликов'].isna()]\n",
    "data_cleaned = data.dropna(subset=['название_канала', 'описание_канала', 'Названия_видео_роликов'])\n",
    "\n",
    "print(f\"Размер оригинального датасета: {data.shape}\")\n",
    "print(f\"Размер очищенного датасета: {data_cleaned.shape}\")\n",
    "\n",
    "data = data_cleaned"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:19:11.662398Z",
     "start_time": "2024-02-21T08:18:56.032447Z"
    }
   },
   "id": "98ca4735221672d4"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "           название_канала                                    ссылка_на_канал  \\\n0                       A4  http://www.youtube.com/channel/UC2tsySbe9TNrI-...   \n1          Kuplinov ► Play  http://www.youtube.com/channel/UCdKuE7a2QZeHPh...   \n2      Натурал Альбертович  http://www.youtube.com/channel/UCE7f6y9VGVdZEt...   \n3                ExileShow  http://www.youtube.com/channel/UC6JRrn_7Qe1CZB...   \n4            Gufee.medalin  http://www.youtube.com/channel/UC7VUPJfRyt57Xo...   \n..                     ...                                                ...   \n95              Yan Reyzen  http://www.youtube.com/channel/UC85pOvkr5egVA3...   \n96        ° ๑ Чудо-Чай ๑ °  http://www.youtube.com/channel/UCBVtlxZExSEsia...   \n97             MILANA STAR  http://www.youtube.com/channel/UCBpKZtuLooxjSm...   \n98  А на даче жизнь иначе!  http://www.youtube.com/channel/UCXk07_I__uaDYi...   \n99        Диана Анкудинова  http://www.youtube.com/channel/UCgbtr4QB6kk7Wa...   \n\n                                      описание_канала  \\\n0   канал называется а почему так тебе нужно зайти...   \n1   здесь можно поржать отложить кирпичей снять ст...   \n2                            всем спасибо за подписку   \n3   я не знаю зачем создал этот канал но он вроде ...   \n4                       самый молодой режиссёр страны   \n..                                                ...   \n95                     всем привет с вами ян рейзен с   \n96           всем морковный привет меня зовут чудочай   \n97  официальный youtube канал юной певицы milana star   \n98                                           телеграм   \n99  добро пожаловать на youtubeканал певицы дианы ...   \n\n                               Названия_видео_роликов         метка_класса  \\\n0   заданий за часа челлендж часть типы братьев и ...  [Развлечения, Юмор]   \n1   предатель  resident evil hd remaster вселенная...         [Юмор, Игры]   \n2   смешные видео сборник юмор и приколы свежие см...               [Юмор]   \n3   самый везучий выиграет горилла кореш коффи дил...        [Развлечения]   \n4   третий этап отношений трейлер сериала премьера...               [Кино]   \n..                                                ...                  ...   \n95  как я отметил февраля в другой стране и пожале...        [Развлечения]   \n96  обби на двоих с холибамом teamwork puzzles hol...               [Игры]   \n97  milana star хит малявка официальное видео mila...             [Музыка]   \n98  декабря г сохраняю и размножаю махровый львины...          [Лайфстайл]   \n99  диана анкудинова получила золотую кнопку youtu...             [Музыка]   \n\n   метка_класса_id                                      combined_text  \n0          [8, 10]  A4 канал называется а почему так тебе нужно за...  \n1          [10, 3]  Kuplinov ► Play здесь можно поржать отложить к...  \n2             [10]  Натурал Альбертович всем спасибо за подписку с...  \n3              [8]  ExileShow я не знаю зачем создал этот канал но...  \n4              [9]  Gufee.medalin самый молодой режиссёр страны тр...  \n..             ...                                                ...  \n95             [8]  Yan Reyzen всем привет с вами ян рейзен с как ...  \n96             [3]  ° ๑ Чудо-Чай ๑ ° всем морковный привет меня зо...  \n97             [4]  MILANA STAR официальный youtube канал юной пев...  \n98             [1]  А на даче жизнь иначе! телеграм декабря г сохр...  \n99             [4]  Диана Анкудинова добро пожаловать на youtubeка...  \n\n[100 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>название_канала</th>\n      <th>ссылка_на_канал</th>\n      <th>описание_канала</th>\n      <th>Названия_видео_роликов</th>\n      <th>метка_класса</th>\n      <th>метка_класса_id</th>\n      <th>combined_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A4</td>\n      <td>http://www.youtube.com/channel/UC2tsySbe9TNrI-...</td>\n      <td>канал называется а почему так тебе нужно зайти...</td>\n      <td>заданий за часа челлендж часть типы братьев и ...</td>\n      <td>[Развлечения, Юмор]</td>\n      <td>[8, 10]</td>\n      <td>A4 канал называется а почему так тебе нужно за...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Kuplinov ► Play</td>\n      <td>http://www.youtube.com/channel/UCdKuE7a2QZeHPh...</td>\n      <td>здесь можно поржать отложить кирпичей снять ст...</td>\n      <td>предатель  resident evil hd remaster вселенная...</td>\n      <td>[Юмор, Игры]</td>\n      <td>[10, 3]</td>\n      <td>Kuplinov ► Play здесь можно поржать отложить к...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Натурал Альбертович</td>\n      <td>http://www.youtube.com/channel/UCE7f6y9VGVdZEt...</td>\n      <td>всем спасибо за подписку</td>\n      <td>смешные видео сборник юмор и приколы свежие см...</td>\n      <td>[Юмор]</td>\n      <td>[10]</td>\n      <td>Натурал Альбертович всем спасибо за подписку с...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ExileShow</td>\n      <td>http://www.youtube.com/channel/UC6JRrn_7Qe1CZB...</td>\n      <td>я не знаю зачем создал этот канал но он вроде ...</td>\n      <td>самый везучий выиграет горилла кореш коффи дил...</td>\n      <td>[Развлечения]</td>\n      <td>[8]</td>\n      <td>ExileShow я не знаю зачем создал этот канал но...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Gufee.medalin</td>\n      <td>http://www.youtube.com/channel/UC7VUPJfRyt57Xo...</td>\n      <td>самый молодой режиссёр страны</td>\n      <td>третий этап отношений трейлер сериала премьера...</td>\n      <td>[Кино]</td>\n      <td>[9]</td>\n      <td>Gufee.medalin самый молодой режиссёр страны тр...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>Yan Reyzen</td>\n      <td>http://www.youtube.com/channel/UC85pOvkr5egVA3...</td>\n      <td>всем привет с вами ян рейзен с</td>\n      <td>как я отметил февраля в другой стране и пожале...</td>\n      <td>[Развлечения]</td>\n      <td>[8]</td>\n      <td>Yan Reyzen всем привет с вами ян рейзен с как ...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>° ๑ Чудо-Чай ๑ °</td>\n      <td>http://www.youtube.com/channel/UCBVtlxZExSEsia...</td>\n      <td>всем морковный привет меня зовут чудочай</td>\n      <td>обби на двоих с холибамом teamwork puzzles hol...</td>\n      <td>[Игры]</td>\n      <td>[3]</td>\n      <td>° ๑ Чудо-Чай ๑ ° всем морковный привет меня зо...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>MILANA STAR</td>\n      <td>http://www.youtube.com/channel/UCBpKZtuLooxjSm...</td>\n      <td>официальный youtube канал юной певицы milana star</td>\n      <td>milana star хит малявка официальное видео mila...</td>\n      <td>[Музыка]</td>\n      <td>[4]</td>\n      <td>MILANA STAR официальный youtube канал юной пев...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>А на даче жизнь иначе!</td>\n      <td>http://www.youtube.com/channel/UCXk07_I__uaDYi...</td>\n      <td>телеграм</td>\n      <td>декабря г сохраняю и размножаю махровый львины...</td>\n      <td>[Лайфстайл]</td>\n      <td>[1]</td>\n      <td>А на даче жизнь иначе! телеграм декабря г сохр...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Диана Анкудинова</td>\n      <td>http://www.youtube.com/channel/UCgbtr4QB6kk7Wa...</td>\n      <td>добро пожаловать на youtubeканал певицы дианы ...</td>\n      <td>диана анкудинова получила золотую кнопку youtu...</td>\n      <td>[Музыка]</td>\n      <td>[4]</td>\n      <td>Диана Анкудинова добро пожаловать на youtubeка...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T16:16:00.085425Z",
     "start_time": "2024-02-20T16:16:00.080979Z"
    }
   },
   "id": "8ad61f6f6e92ab59"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимальная длина текста: 2\n",
      "Максимальная длина текста: 1728\n",
      "Средняя длина текста: 262.3183377811666\n",
      "Медианная длина текста: 162.0\n",
      "Количество меток: 11\n",
      "Пример меток: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "Размер labels_encoded: (5246, 11)\n",
      "Количество строк в исходных данных: 5246\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "text_lengths = [len(text.split()) for text in data['combined_text'].values]\n",
    "\n",
    "min_length = min(text_lengths)\n",
    "max_length = max(text_lengths)\n",
    "average_length = sum(text_lengths) / len(text_lengths)\n",
    "median_length = np.median(text_lengths)\n",
    "\n",
    "print(f\"Минимальная длина текста: {min_length}\")\n",
    "print(f\"Максимальная длина текста: {max_length}\")\n",
    "print(f\"Средняя длина текста: {average_length}\")\n",
    "print(\"Медианная длина текста:\", median_length)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_encoded = mlb.fit_transform(data['метка_класса_id'])\n",
    "\n",
    "print(\"Количество меток:\", len(mlb.classes_))\n",
    "print(\"Пример меток:\", mlb.classes_)\n",
    "\n",
    "print(\"Размер labels_encoded:\", labels_encoded.shape)\n",
    "print(\"Количество строк в исходных данных:\", data.shape[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T15:16:47.035711Z",
     "start_time": "2024-02-20T15:16:46.944528Z"
    }
   },
   "id": "75cd0febedc276ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bert"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87beda437619782e"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_one_hot = mlb.fit_transform(data['метка_класса_id'].values)\n",
    "\n",
    "dataset = CustomDataset(data['combined_text'].values, labels_one_hot, tokenizer)\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:44:10.806845Z",
     "start_time": "2024-02-21T08:44:10.390651Z"
    }
   },
   "id": "537ddd6fb97583e5"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([   101,  38846,  41308,  61722,    541,  10297,  96506,  12123,  13613,\n          18106,  71004,  10234,  37756,  10122,  13981,  10297,  10513, 104722,\n         101312,  66457,  10227,  43428,    549,  31816,  79141,  10297,  64361,\n          31751,  10851,    543,  18658,  29112,  10122, 110040,  79141,  16541,\n          94837,  63307,  66793,  59075,  11050,  66457,  12751,  12968,  41073,\n            557,  18291,  12184,  15920,  10351,  13613,  18106,  10791,  10656,\n          91369,  59075,  12621,    557,  18291,  10513,  14689,  13523,  10351,\n            549,  31108,  11429,  13126,  11613,  32001,  62735,  16241,  11429,\n          29678,  10292,  37914,  10625,    549,  66345,  15683,  11833,  18261,\n          10993,  51801,  10234,  60461,  10234,  54875,  25877,  50702,  12025,\n          15848,  20844,  10292, 102370,    549,  10277,  24519,    558,  97205,\n          10433,  12709,  74223,  52399,  20004,  26990,    543,    559,  10593,\n          28301,  11805,  22504,  55580,  97744,  23739, 103909,  18291,  13391,\n          10746,  23352,  76606,  12751,  20346,    570,  18705,  46672,  27926,\n          22988,  25484,  13081,  10648,    543,  97744,  10695,  34968,  12588,\n          65304,  96734,  10880,  50818,  19557,  22439,  12634,  15116,  25877,\n          50702,  12025,  54875,    543,    549,  10823,  16111,  96195,  52895,\n          27473,  12562,    543,  22141,    570,  18705,  46672,  27926,  22988,\n          25484,  13081,  10648,  10956,    558,  52601,  52086,  49388,    541,\n            560,  40339,  50272,    557,  89317,  10587,  29633,  28826,  11292,\n          32073, 103909,  18291,  13391,  10746,  23352,  10913,  24373,  25877,\n          50702,  12025,  68813,  10510,  37485,  62408,  22439,    541,  10297,\n          18106,  10823,  10387,  10375, 104082,  98208,  78109,  40139,  10656,\n          25877,  50702,  12025,  46920,  37178,  10155,    169,  18528,  54875,\n            543,  11323,  81273,  50649,  10227,  25877,  50702,  12025,  10297,\n          18106,  10823,  10387,  95582,  48266,    559,  10593,  28301,  15657,\n          25877,  50702,  12025,  15848,  86701,  29627,  10122,  10521,  15920,\n          10351,    554,  18971,  10385,  91258,  70377,    133,  10854,  10129,\n            135,  25877,  50702,  12025,  54875,    543,  21487,  33284,  10122,\n          56572,  10205,  10234,  59221,  10191,  16246,  13081,  10297,  86613,\n          33191,  10241,  13686,  16520,  42128,  54875,  25877,  50702,  12025,\n          11429, 103762,  47779,  58056,  11899,    549,  13721,  22164,  13613,\n          12528,  10385,    558,  36168,  11613,  54875,  11495,  29973,  10593,\n          10405,    553,  49238,  99220,  23043,  10227,    558,  30318,  18400,\n          56280,  57851,  11550,  10234,  54875,  25877,  50702,  12025,  15649,\n          14814,  89666,  95582, 104740,  30977,  34885,  25877,  50702,  12025,\n          10234,  60461,  10234,  54875,  25877,  50702,  12025,  10475,  69657,\n          10353,  14919,  34858,    549,  13721,  22164,  13613,  12528,  10385,\n            558,  36168,  11613,    102,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]),\n 'labels': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.])}"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T09:55:28.252939Z",
     "start_time": "2024-02-20T09:55:28.241094Z"
    }
   },
   "id": "5d61517506457baf"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 9.07 GB, other allocations: 688.00 KB, max allowed: 9.07 GB). Tried to allocate 350.24 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[34], line 49\u001B[0m\n\u001B[1;32m     46\u001B[0m model\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m# Инициализация Trainer с обновленной функцией вычисления метрик\u001B[39;00m\n\u001B[0;32m---> 49\u001B[0m trainer \u001B[38;5;241m=\u001B[39m \u001B[43mTrainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# Обучение и сохранение модели\u001B[39;00m\n\u001B[1;32m     58\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[0;32m~/Desktop/Test_Media/venv/lib/python3.11/site-packages/transformers/trainer.py:459\u001B[0m, in \u001B[0;36mTrainer.__init__\u001B[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001B[0m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001B[39;00m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mplace_model_on_device\n\u001B[1;32m    457\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquantization_method\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m QuantizationMethod\u001B[38;5;241m.\u001B[39mBITS_AND_BYTES\n\u001B[1;32m    458\u001B[0m ):\n\u001B[0;32m--> 459\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_move_model_to_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001B[39;00m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_model_parallel:\n",
      "File \u001B[0;32m~/Desktop/Test_Media/venv/lib/python3.11/site-packages/transformers/trainer.py:693\u001B[0m, in \u001B[0;36mTrainer._move_model_to_device\u001B[0;34m(self, model, device)\u001B[0m\n\u001B[1;32m    692\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_move_model_to_device\u001B[39m(\u001B[38;5;28mself\u001B[39m, model, device):\n\u001B[0;32m--> 693\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    694\u001B[0m     \u001B[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001B[39;00m\n\u001B[1;32m    695\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mparallel_mode \u001B[38;5;241m==\u001B[39m ParallelMode\u001B[38;5;241m.\u001B[39mTPU \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtie_weights\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/Desktop/Test_Media/venv/lib/python3.11/site-packages/transformers/modeling_utils.py:2595\u001B[0m, in \u001B[0;36mPreTrainedModel.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2590\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dtype_present_in_args:\n\u001B[1;32m   2591\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   2592\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2593\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2594\u001B[0m         )\n\u001B[0;32m-> 2595\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Test_Media/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1152\u001B[0m, in \u001B[0;36mModule.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1148\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1149\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m   1150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[0;32m-> 1152\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Test_Media/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    800\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    801\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 802\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    804\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    806\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    807\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    812\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    813\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Test_Media/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    800\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    801\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 802\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    804\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    806\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    807\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    812\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    813\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Test_Media/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    800\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    801\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 802\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    804\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    805\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    806\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    807\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    812\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    813\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Test_Media/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:825\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    821\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[1;32m    822\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[1;32m    823\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[1;32m    824\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 825\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    826\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[1;32m    827\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[0;32m~/Desktop/Test_Media/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1150\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m   1148\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1149\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m-> 1150\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: MPS backend out of memory (MPS allocated: 9.07 GB, other allocations: 688.00 KB, max allowed: 9.07 GB). Tried to allocate 350.24 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, BertForSequenceClassification\n",
    "from transformers import BertTokenizerFast\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probabilities = torch.sigmoid(torch.tensor(logits)).numpy()\n",
    "    predictions = (probabilities > 0.5).astype(int)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='micro')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-multilingual-cased',\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    num_labels=len(unique_classes)\n",
    ")\n",
    "\n",
    "model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"./best_model\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50bb3e6d0bd6bf8b"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T09:57:27.414349Z",
     "start_time": "2024-02-20T09:57:27.402062Z"
    }
   },
   "id": "11951de7bf04eb32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f1a45d2c5842be51"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
